# Computerlinguistische Anwendungen
### Anwendung maschineller Lernverfahren in Python
### Sommersemester 2018
### Centrum für Informations- und Sprachverarbeitung, LMU München

 - Zeit/Vorlesung: Mi 14:00-17-00 (c.t.)
 - Ort/Vorlesung: Hörsaal L 155, Oettingenstr. 67
 - Zeit/Übung: Do 14:00-16:00 (c.t.)
 - Ort/Übung: CIP Pool (Sibirien/Gobi)

 - Dozenten: Benjamin Roth, Marina Sedinkina
 - Tutoren: Daniel Weber, Felip Guimerà Cuevas, Ziad Elsayes 
 
 
Sie erreichen den Dozenten und die Tutoren unter:

cla2018 [at] cis [dot] uni [minus] muenchen [dot] de

Anmeldung zur Vorlesung:
 - Studenten mit Computerlinguistik als Hauptfach, und nicht-Informatiker melden sich bitte über das LSF zur Vorlesung an.
 - Studenten mit Informatik als Hauptfach benutzen bitte das [Webformular](https://goo.gl/forms/xt5xpQzjRWZGKeU42){:target="_blank"}
 
 Für die Übungen benötigen Sie einen GitLab Account des IFI:  [Mehr Informationen](http://www.rz.ifi.lmu.de/Dienste/Gitlab.html){:target="_blank"}

Übungen werden in Teams aus 2 oder 3 Teilnehmern gebildet. Sie können ein Team hier anmelden: [Webformular](https://goo.gl/forms/NqfDSS0jkEcgSQxJ3){:target="_blank"}


| Date | slides | homework | materials |
|-----------------------------|:--------------------------------:|:------:|:-------------------------------------------------------------------|
| - |  |  | [PyCharm Intro (optional, jedoch vorteilhaft zur Übungsbearbeitung)](pycharm.pdf){:target="_blank"} |
| 11.4. | [Course Overview](01_overview.pdf){:target="_blank"}; [Machine Learning Basics](01_machine_learning.pdf){:target="_blank"}; [Perzeptron](01_perceptron_short.pdf){:target="_blank"} |  | Literatur: Hal Daume [(pdf)](http://www.ciml.info/dl/v0_99/ciml-v0_99-ch04.pdf){:target="_blank"} |
| 12.4. |  | [Homework 1](hw01_perceptron.pdf){:target="_blank"} | [enron.tgz](http://www.cis.uni-muenchen.de/~beroth/cla/enron.tgz){:target="_blank"} |
| 18.4. | Naive Bayes; Multiclass Classification |  |  |
| 25.4. | Numpy; Scikit-Learn |  |  |
| 2.5. | MaxEnt Klassifikator; SVM; Wort-Repräsentationen 1  |  |  |
| 9.5. | Wort-Repräsentationen 2 |  |  |
| 16.5. | Implementierung von Wortähnlichkeit |  |  |
| 23.5. | Skipgram (Word2Vec) |  |  |
| 30.5. | Fasttext; SGD; Visualisierung; Anwendung von Wortvektoren |  |  |
| 6.6. | Neuronale Netzwerke 1 |  |  |
| 13.6. | Neuronale Netzwerke 2 |  |  |
| 20.6. | TBD |  |  |
| 27.6. | TBD |  |  |
| 4.7. | Fragestunde |  |  |
| 11.7. | Klausur |  |  |

